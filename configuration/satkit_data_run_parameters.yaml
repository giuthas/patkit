##
## Copyright (c) 2019-2023 
## Pertti Palo, Scott Moisik, Matthew Faytak, and Motoki Saito.
##
## This file is part of Speech Articulation ToolKIT 
## (see https://github.com/giuthas/satkit/).
##
## This program is free software: you can redistribute it and/or modify
## it under the terms of the GNU General Public License as published by
## the Free Software Foundation, either version 3 of the License, or
## (at your option) any later version.
##
## This program is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU General Public License for more details.
##
## You should have received a copy of the GNU General Public License
## along with this program. If not, see <http://www.gnu.org/licenses/>.
##
## The example data packaged with this program is licensed under the
## Creative Commons Attribution-NonCommercial-ShareAlike 4.0
## International (CC BY-NC-SA 4.0) License. You should have received a
## copy of the Creative Commons Attribution-NonCommercial-ShareAlike 4.0
## International (CC BY-NC-SA 4.0) License along with the data. If not,
## see <https://creativecommons.org/licenses/by-nc-sa/4.0/> for details.
##
## When using the toolkit for scientific publications, please cite the
## articles listed in README.markdown. They can also be found in
## citations.bib in BibTeX format.
##

# Please note that empty file or directory fields are
# interpeted as not available and represented by None. If you want to specify
# current working directory, use '.'

flags:
  detect beep: True # Should onset beep detection be run?
  test: False # Run on only the first 10 recordings.

# This is where SATKIT will save results of data processing. Please note that
# once exclusion list or similar things can be edited in SATKIT, they will by
# default be saved at their original locations.
output directory:

# Config for the yet-to-happen submodule CAST that is still a separate entity. 
cast:
  # Consists of words followed by their segments in arbitrary transcription.  
  pronunciation dictionary: local_data/gam_mono_and_disyllables_for_automatic_segmentation.csv

  # Speaker id is used in the output csv file.
  speaker id: gam-1-2

  cast flags:
    only words: False # Add only Utterance and Word Tiers.
    utterance: True # Add Utterance Tier.
    file: False # Add File Tier.
